{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "import os\n",
    "from os.path import join\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_message = pd.read_csv(\"./smsspamcollection/SMSSpamCollection\",sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 2)\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df_message.shape\n",
    "print df_message[:5]\n",
    "print df_message.message[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'u', u'dun', u'say', u'so', u'early', u'hor', u'u', u'c', u'already', u'then', u'say']\n"
     ]
    }
   ],
   "source": [
    "#test blob using ---------------------\n",
    "message_test= \"U dun say so early hor... U c already then say...\"\n",
    "message_test = unicode(message_test,'utf8').lower()\n",
    "words = TextBlob(message_test).words\n",
    "print words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'u', u'dun', u'say', u'so', u'early', u'hor', u'u', u'c', u'already', u'then', u'say']\n"
     ]
    }
   ],
   "source": [
    "print [word.lemma for word in words]\n",
    "#end of test blob----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message = unicode(message, 'utf8').lower()\n",
    "    words = TextBlob(message).words\n",
    "    return [word.lemma for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=<function split_into_lemmas at 0x10ba94050>,\n",
      "        binary=False, charset=None, charset_error=None,\n",
      "        decode_error=strict, dtype=<type 'numpy.int64'>, encoding=utf-8,\n",
      "        input=content, lowercase=True, max_df=1.0, max_features=None,\n",
      "        min_df=1, ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=(?u)\\b\\w\\w+\\b, tokenizer=None,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "BOW_transform = CountVectorizer(analyzer=split_into_lemmas)\n",
    "print BOW_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function split_into_lemmas at 0x10ba94050>,\n",
       "        binary=False, charset=None, charset_error=None,\n",
       "        decode_error=u'strict', dtype=<type 'numpy.int64'>,\n",
       "        encoding=u'utf-8', input=u'content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=None, strip_accents=None,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_transform.fit(df_message['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=word, binary=False, charset=None, charset_error=None,\n",
      "        decode_error=strict, dtype=<type 'numpy.int64'>, encoding=utf-8,\n",
      "        input=content, lowercase=True, max_df=1.0, max_features=None,\n",
      "        min_df=1, ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=(?u)\\b\\w\\w+\\b, tokenizer=None,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "#using count vectorizer-------------\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "print vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'disk', u'format', u'hard', u'how', u'my', u'problems', u'to']\n",
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "content = [\"How to format my hard disk\", \" Hard disk format problems \"]\n",
    "X = vectorizer.fit_transform(content)\n",
    "print vectorizer.get_feature_names()\n",
    "print(X.toarray().transpose())\n",
    "#count vectorizer end--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "print df_message['message'][2]\n",
    "print df_message['label'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u\"''ok\", u\"'an\", u\"'anything\", u\"'comfort\", u\"'d\"]\n"
     ]
    }
   ],
   "source": [
    "print BOW_transform.get_feature_names()[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 21)\t2\n",
      "  (0, 103)\t1\n",
      "  (0, 452)\t1\n",
      "  (0, 472)\t1\n",
      "  (0, 484)\t1\n",
      "  (0, 893)\t1\n",
      "  (0, 948)\t1\n",
      "  (0, 1272)\t1\n",
      "  (0, 1899)\t1\n",
      "  (0, 2266)\t1\n",
      "  (0, 2479)\t1\n",
      "  (0, 3046)\t2\n",
      "  (0, 3177)\t2\n",
      "  (0, 3287)\t1\n",
      "  (0, 3437)\t1\n",
      "  (0, 4183)\t1\n",
      "  (0, 5029)\t1\n",
      "  (0, 6297)\t1\n",
      "  (0, 6350)\t1\n",
      "  (0, 6408)\t1\n",
      "  (0, 7310)\t1\n",
      "  (0, 7533)\t1\n",
      "  (0, 7647)\t1\n",
      "  (0, 7801)\t1\n",
      "  (0, 7812)\t3\n",
      "  (0, 7996)\t1\n",
      "  (0, 8485)\t1\n",
      "  (0, 8525)\t1\n",
      "length of the vector is: 8874\n"
     ]
    }
   ],
   "source": [
    "print BOW_transform.transform([df_message['message'][2]])\n",
    "print 'length of the vector is:', BOW_transform.transform([df_message['message'][2]]).shape[1]\n",
    "#The third message is transformed in count vectorizer and the postion of each word in the vectotrizer feauture names\n",
    "# is shown and the count of that word in that sentence is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "# the postion of word \"to\" in the vector\n",
    "print BOW_transform.get_feature_names()[7812]\n",
    "\n",
    "#the word \"to\" appears 3 times in the message\n",
    "print df_message['message'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BOW = BOW_transform.transform(df_message['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the large transformed matrix is: (5574, 8874) i.e\n",
      "5574 rows that corresponds to the number of messages and\n",
      "8874 columns for each of the message that corresponds to the total number of unique words in the dataset\n"
     ]
    }
   ],
   "source": [
    "print 'Shape of the large transformed matrix is:', BOW.shape, 'i.e'\n",
    "print BOW.shape[0], 'rows that corresponds to the number of messages and'\n",
    "print BOW.shape[1], 'columns for each of the message that corresponds to the total number of unique words in the dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizing and weighing\n",
    "tfidf_BOW = TfidfTransformer().fit(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8525)\t0.179632904113\n",
      "  (0, 8485)\t0.138190739033\n",
      "  (0, 7996)\t0.118168109475\n",
      "  (0, 7812)\t0.171012810274\n",
      "  (0, 7801)\t0.208159499981\n",
      "  (0, 7647)\t0.11289854213\n",
      "  (0, 7533)\t0.133691560916\n",
      "  (0, 7310)\t0.185427055493\n",
      "  (0, 6408)\t0.157631945365\n",
      "  (0, 6350)\t0.157631945365\n",
      "  (0, 6297)\t0.158384636518\n",
      "  (0, 5029)\t0.148370514297\n",
      "  (0, 4183)\t0.0764098797291\n",
      "  (0, 3437)\t0.109085811318\n",
      "  (0, 3287)\t0.173494826823\n",
      "  (0, 3177)\t0.442847223391\n",
      "  (0, 3046)\t0.339376234237\n",
      "  (0, 2479)\t0.19016122188\n",
      "  (0, 2266)\t0.185427055493\n",
      "  (0, 1899)\t0.119671386057\n",
      "  (0, 1272)\t0.159958817058\n",
      "  (0, 948)\t0.0643973850704\n",
      "  (0, 893)\t0.208159499981\n",
      "  (0, 484)\t0.213953651361\n",
      "  (0, 472)\t0.213953651361\n",
      "  (0, 452)\t0.0944406763398\n",
      "  (0, 103)\t0.221423611696\n",
      "  (0, 21)\t0.183683813193\n"
     ]
    }
   ],
   "source": [
    "print tfidf_BOW.transform(BOW[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverse document frequency of the word \"to\" is: 2.19534051378\n"
     ]
    }
   ],
   "source": [
    "print 'inverse document frequency of the word \"to\" is:', tfidf_BOW.idf_[BOW_transform.vocabulary_['to']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do it with entire bag of words\n",
    "converted_messages = tfidf_BOW.transform(BOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 8874)\n"
     ]
    }
   ],
   "source": [
    "print converted_messages.shape\n",
    "#converted messages store the normalized weights of each word in a row of 8874 words\n",
    "#and 5574 messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8471)\t0.423369271093\n",
      "  (0, 8013)\t0.190655730508\n",
      "  (0, 5660)\t0.536156905844\n",
      "  (0, 5628)\t0.269618808649\n",
      "  (0, 4641)\t0.400512820409\n",
      "  (0, 4431)\t0.513653388721\n",
      "0.190655730508\n"
     ]
    }
   ],
   "source": [
    "print converted_messages[1]\n",
    "print converted_messages[1,8013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "|S6\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print converted_messages.dtype\n",
    "y_train = np.asarray(df_message['label'], dtype=\"|S6\")\n",
    "print y_train.dtype\n",
    "print df_message['label'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time taken in training: 0:00:00.007954\n"
     ]
    }
   ],
   "source": [
    "split = int(0.75 * converted_messages.shape[0])\n",
    "t1 = dt.datetime.now()\n",
    "spam_detector = MultinomialNB().fit(converted_messages[:split], y_train[:split])\n",
    "t2 = dt.datetime.now()\n",
    "print 'total time taken in training:', (t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.005601\n",
      "94.7632711621\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "score = spam_detector.score(converted_messages[split:], y_train[split:])\n",
    "end = dt.datetime.now()\n",
    "print end-start\n",
    "print score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time taken in training: 0:02:51.821790\n"
     ]
    }
   ],
   "source": [
    "split = int(0.75 * converted_messages.shape[0])\n",
    "t1 = dt.datetime.now()\n",
    "spam_detector=RandomForestClassifier(n_estimators=200).fit(converted_messages[:split].toarray(), y_train[:split])\n",
    "t2 = dt.datetime.now()\n",
    "print 'total time taken in training:', (t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time taken in training: 0:06:08.771329\n"
     ]
    }
   ],
   "source": [
    "split = int(0.75 * converted_messages.shape[0])\n",
    "t1 = dt.datetime.now()\n",
    "spam_detector=RandomForestClassifier(n_estimators=400).fit(converted_messages[:split].toarray(), y_train[:split])\n",
    "t2 = dt.datetime.now()\n",
    "print 'total time taken in training:', (t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = int(0.75 * converted_messages.shape[0])\n",
    "t1 = dt.datetime.now()\n",
    "spam_detector=RandomForestClassifier(n_estimators=600).fit(converted_messages[:split].toarray(), y_train[:split])\n",
    "t2 = dt.datetime.now()\n",
    "print 'total time taken in training:', (t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.667909\n",
      "97.0588235294\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "score = spam_detector.score(converted_messages[split:].toarray(), y_train[split:])\n",
    "end = dt.datetime.now()\n",
    "print end-start\n",
    "print score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
